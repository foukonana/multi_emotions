{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification  \n",
    "\n",
    "Often, we may encouter data that can be classified into more than one categories (for example movie genre, items in an image).  \n",
    "However, typical classification tasks involve predicting a single label, as they treat classes as being mutually exclusive.   \n",
    "\n",
    "Multi-Label Classification is the supervised learning problem where an instance may be associated with multiple labels. This is opposed to the traditional task of single-label classification (i.e., multi-class, or binary) where each instance is only associated with a single class label. \n",
    "\n",
    "  \n",
    "\n",
    "### Techniques   \n",
    "\n",
    "There are two main categorizations of methods that can be used to solve for the multi-label classification problem  \n",
    "* problem transformation methods and \n",
    "* algorithm adaptation methods \n",
    "\n",
    "In the first case the learning task is transformed into more or single-label classification tasks. \n",
    "In the second, the algorithms are adapted so that they can handle multi-label data.   \n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "The dataset used here is the GoEmotions.  \n",
    "This is a dataset released from Google and it containes the emotions detected in those texts.  \n",
    "It is the largest manually annotated dataset of 58K English Reddit comments, labeled for 27 emotion categories or neutral.  \n",
    "Find the paper on [arXiv.org](https://arxiv.org/abs/2005.00547)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "import re \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pathlib.Path.cwd() / 'Datasets/train.tsv'\n",
    "df = pd.read_csv(dataset, sep='\\t', header=None, names=['comment', 'label', 'id'])\n",
    "df['label'] = df['label'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment',                     \n",
    "                'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',                 \n",
    "                'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
    "\n",
    "enkman_mapping = {\n",
    "        \"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "        \"disgust\": [\"disgust\"],\n",
    "        \"fear\": [\"fear\", \"nervousness\"],\n",
    "        \"joy\": [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
    "        \"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "        \"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"],\n",
    "        \"neutral\": [\"neutral\"],\n",
    "        }\n",
    "enkman_mapping_rev = {v:key for key, value in enkman_mapping.items() for v in value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from Google Research analysis \n",
    "def idx2class(idx_list):\n",
    "    arr = []\n",
    "    for i in idx_list:\n",
    "        arr.append(emotion_list[int(i)])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add emotion label to the label ids\n",
    "df['emotions'] = df['label'].apply(idx2class)\n",
    "\n",
    "# use enkman mapping to reduce the emotions to a list of ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "df['mapped_emotions'] = df['emotions'].apply(lambda x: [enkman_mapping_rev[i] for i in x])\n",
    "\n",
    "# fix issues where ['joy',' joy'] might appear\n",
    "df.loc[df['mapped_emotions'].apply(len)>1, 'mapped_emotions'] = df.loc[df['mapped_emotions'].apply(len)>1, 'mapped_emotions'].apply(lambda x: [emotion for emotion in set(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(simple) text pre-processing and TF_IDF representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTICE_   \n",
    "r/ represents a reddit category   \n",
    "Example: 'r/hockey has no love for us! Just stay here with all us cool people!'\n",
    "\n",
    "\\[NAME] is replaced from a word that may be representing a brand or a person  \n",
    "Example: 'How have \\[NAME] and \\[NAME] looked tonight? I was watching the Huskies game during the first period.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "\n",
    "def process_reddit_comment(strng):\n",
    "    # remove [NAME] placeholder\n",
    "    processed_strng = re.sub('\\[name]', '', strng)\n",
    "    # remove reddit symbol \n",
    "    processed_strng = re.sub('/r', '', processed_strng)\n",
    "    return processed_strng\n",
    "\n",
    "\n",
    "def punct_remover(strng):\n",
    "    # punctuation marks to be completely removed\n",
    "    clean_strng = re.sub(r'[?|!|\\'|\"|#]', r'', strng)\n",
    "    # punctuation marks to be replaced with space\n",
    "    clean_strng = re.sub(r'[.|,|)|(|\\|/]', r' ', clean_strng)\n",
    "    # replace multi-space with single space \n",
    "    clean_strng = re.sub(r' +', r' ', clean_strng)\n",
    "\n",
    "    return clean_strng\n",
    "\n",
    "\n",
    "def tokenize_stem_no_stopwords(strng):\n",
    "    return [stemmer.stem(w) for w in word_tokenize(strng) if w not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase and remove punctuation \n",
    "df['processed_comment'] = df['comment'].str.lower()\n",
    "df['processed_comment'] = df['processed_comment'].apply(process_reddit_comment)\n",
    "df['processed_comment'] = df['processed_comment'].apply(punct_remover)\n",
    "df['processed_comment'] = df['processed_comment'].apply(tokenize_stem_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiments are represented in the columns.  \n",
    "If a reddit post is classified as having x sentiment, then we represent it with an 1 in x column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.shape[0]\n",
    "for emotion in enkman_mapping.keys():\n",
    "    df[emotion] = np.zeros((N,1), dtype=int)\n",
    "\n",
    "for emotion in enkman_mapping.keys():\n",
    "    df[emotion] = df['mapped_emotions'].apply(lambda x: 1 if emotion in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, random_state=156, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "\n",
    "x_train = tfidf.fit_transform(X_train['processed_comment'].apply(lambda x: ' '.join(x)))\n",
    "x_test = tfidf.transform(X_test['processed_comment'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, label_ranking_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset\n",
    "from skmultilearn.ensemble import RakelD, RakelO\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRest classification for the emotion of anger\n",
      "Accuracy on anger is 88.12% \n",
      "\n",
      "OneVsRest classification for the emotion of disgust\n",
      "Accuracy on disgust is 98.14% \n",
      "\n",
      "OneVsRest classification for the emotion of fear\n",
      "Accuracy on fear is 98.28% \n",
      "\n",
      "OneVsRest classification for the emotion of joy\n",
      "Accuracy on joy is 82.13% \n",
      "\n",
      "OneVsRest classification for the emotion of sadness\n",
      "Accuracy on sadness is 93.56% \n",
      "\n",
      "OneVsRest classification for the emotion of surprise\n",
      "Accuracy on surprise is 88.30% \n",
      "\n",
      "OneVsRest classification for the emotion of neutral\n",
      "Accuracy on neutral is 72.37% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for emotion in enkman_mapping.keys():\n",
    "    print(f'OneVsRest classification for the emotion of {emotion}')\n",
    "    clf = OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)\n",
    "    clf.fit(x_train, X_train[emotion])\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(f'Accuracy on {emotion} is {accuracy_score(X_test[emotion], y_pred)*100:.2f}% \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem transformation methods \n",
    "1. Binary Relevance\n",
    "2. ClassifierChain\n",
    "3. Laber powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 5.06% \n",
      "\n",
      "Hamming loss is 46.58% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "clf = BinaryRelevance(GaussianNB())\n",
    "clf.fit(x_train, X_train[enkman_mapping.keys()])\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')\n",
    "print(f'Hamming loss is {hamming_loss(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 5.15% \n",
      "\n",
      "Hamming loss is 46.52% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "clf = ClassifierChain(classifier=GaussianNB())\n",
    "clf.fit(x_train, X_train[enkman_mapping.keys()])\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')\n",
    "print(f'Hamming loss is {metrics.hamming_loss(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 13.47% \n",
      "\n",
      "Hamming loss is 25.34% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import  LabelPowerset\n",
    "\n",
    "clf = LabelPowerset(classifier=GaussianNB())\n",
    "clf.fit(x_train, X_train[enkman_mapping.keys()])\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')\n",
    "print(f'Hamming loss is {hamming_loss(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.ext import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model_single_class(input_dim, output_dim):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arafi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 40.73% \n",
      "\n",
      "Hamming loss is 13.61% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "KERAS_PARAMS = dict(epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "clf = BinaryRelevance(classifier=Keras(create_model_single_class, False, KERAS_PARAMS), require_dense=[True,True])\n",
    "clf.fit(x_train, X_train[enkman_mapping.keys()])\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')\n",
    "print(f'Hamming loss is {hamming_loss(X_test[enkman_mapping.keys()], y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Adaptation methods \n",
    "1. BRkNNaClassifier\n",
    "2. BRkNNbClassifier\n",
    "3. MLkNN\n",
    "4. MLTSVM\n",
    "\n",
    "A toy data will be used for time efficiency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "\n",
    "X_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
    "X_test, y_test, _, _ = load_dataset('emotions', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 19.31% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "clf = BRkNNaClassifier(k=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(y_test, y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 4.46% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNbClassifier\n",
    "\n",
    "clf = BRkNNbClassifier(k=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(y_test, y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 19.31% \n",
      "\n",
      "Hamming loss is 29.54% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "clf = MLkNN(k=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(y_test, y_pred)*100:.2f}% \\n')\n",
    "print(f'Hamming loss is {hamming_loss(y_test, y_pred)*100:.2f}% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arafi\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:318: SparseEfficiencyWarning: splu requires CSC matrix format\n",
      "  warn('splu requires CSC matrix format', SparseEfficiencyWarning)\n",
      "C:\\Users\\arafi\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:215: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 7.43% \n",
      "\n",
      "Ranking Loss is 78.29% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLTSVM\n",
    "\n",
    "clf =  MLTSVM(c_k = 2**-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score is {accuracy_score(y_test, y_pred)*100:.2f}% \\n')\n",
    "print(f'Ranking Loss is {label_ranking_loss(y_test, y_pred)*100:.2f}% \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
